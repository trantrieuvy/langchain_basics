{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().date()\n",
    "target_time = datetime.date(2024, 6, 12)\n",
    "if current_time > target_time:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name is Vy\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Vy! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, my name is Vy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Vy\n",
      "AI: Hello Vy! It's nice to meet you. How can I assist you today?\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or Assistant.\n",
      "Human: What do you know about Continental Tires\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Continental Tires is a German automotive manufacturing company that specializes in producing tires for various vehicles, including cars, trucks, and motorcycles. They are known for their high-quality tires that offer excellent performance and durability. Continental Tires has a long history in the industry, dating back to 1871 when the company was founded. They are one of the largest tire manufacturers in the world and have a strong reputation for innovation and technology in tire design. Is there anything specific you would like to know about Continental Tires?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What do you know about Continental Tires\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Vy\n",
      "AI: Hello Vy! It's nice to meet you. How can I assist you today?\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or Assistant.\n",
      "Human: What do you know about Continental Tires\n",
      "AI: Continental Tires is a German automotive manufacturing company that specializes in producing tires for various vehicles, including cars, trucks, and motorcycles. They are known for their high-quality tires that offer excellent performance and durability. Continental Tires has a long history in the industry, dating back to 1871 when the company was founded. They are one of the largest tire manufacturers in the world and have a strong reputation for innovation and technology in tire design. Is there anything specific you would like to know about Continental Tires?\n",
      "Human: What is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name. If you would like to share it with me, I can certainly remember it for future conversations.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Vy\n",
      "AI: Hello Vy! It's nice to meet you. How can I assist you today?\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or Assistant.\n",
      "Human: What do you know about Continental Tires\n",
      "AI: Continental Tires is a German automotive manufacturing company that specializes in producing tires for various vehicles, including cars, trucks, and motorcycles. They are known for their high-quality tires that offer excellent performance and durability. Continental Tires has a long history in the industry, dating back to 1871 when the company was founded. They are one of the largest tire manufacturers in the world and have a strong reputation for innovation and technology in tire design. Is there anything specific you would like to know about Continental Tires?\n",
      "Human: What is my name\n",
      "AI: I'm sorry, I do not have access to personal information such as your name. If you would like to share it with me, I can certainly remember it for future conversations.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello, my name is Vy\\nAI: Hello Vy! It's nice to meet you. How can I assist you today?\\nHuman: What is your name?\\nAI: I am an AI assistant, so I don't have a personal name like humans do. You can just call me AI or Assistant.\\nHuman: What do you know about Continental Tires\\nAI: Continental Tires is a German automotive manufacturing company that specializes in producing tires for various vehicles, including cars, trucks, and motorcycles. They are known for their high-quality tires that offer excellent performance and durability. Continental Tires has a long history in the industry, dating back to 1871 when the company was founded. They are one of the largest tire manufacturers in the world and have a strong reputation for innovation and technology in tire design. Is there anything specific you would like to know about Continental Tires?\\nHuman: What is my name\\nAI: I'm sorry, I do not have access to personal information such as your name. If you would like to share it with me, I can certainly remember it for future conversations.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Do you like the Beatles?\"},\n",
    "                    {\"output\":\"Yes, I like the Beatles.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do you like the Beatles?\n",
      "AI: Yes, I like the Beatles.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Do you like the Beatles?\\nAI: Yes, I like the Beatles.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"How about the Rolling Stone?\"},\n",
    "                    {\"output\":\"No, I am not a big fan.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Do you like the Beatles?\\nAI: Yes, I like the Beatles.\\nHuman: How about the Rolling Stone?\\nAI: No, I am not a big fan.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "print(memory.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Do you like the Beatles?\"},\n",
    "                    {\"output\":\"Yes, I like the Beatles.\"})\n",
    "memory.save_context({\"input\":\"How about the Rolling Stone?\"},\n",
    "                    {\"output\":\"No, I am not a big fan.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: How about the Rolling Stone?\\nAI: No, I am not a big fan.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
    "memory = ConversationBufferWindowMemory(k=10)\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! That's a cute name for a dog. How old is Bon Bon?\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my dog's name is Bon Bon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2. So, how old is Bon Bon?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your dog's name is Bon Bon. How old is Bon Bon?\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my dog's name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit = 60)    \n",
    "memory.max_token_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Animated films are what?\"},\n",
    "                    {\"output\":\"Fun.\"})\n",
    "memory.save_context({\"input\":\"Blur is a band from where?\"},\n",
    "                    {\"output\":\"England.\"})\n",
    "memory.save_context({\"input\":\"Chess is a game of what?\"},\n",
    "                    {\"output\":\"Strategy.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Animated films are what?\\nAI: Fun.\\nHuman: Blur is a band from where?\\nAI: England.\\nHuman: Chess is a game of what?\\nAI: Strategy.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"I have a meeting at 9am. Then I have a lunch at 12pm. After that, I have a meeting at 2pm. I have a dinner at 6pm. I have a meeting at 8pm. I have a meeting at 10pm. I have a meeting at 11pm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI with a hello and the AI responds by asking what\\'s up. The human replies, \"Not much, just hanging.\" The AI says \"Cool\" and the human asks about the schedule for the day. The AI lists a series of meetings and meals throughout the day.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI with a hello and the AI responds by asking what's up. The human replies, \"Not much, just hanging.\" The AI says \"Cool\" and the human asks about the schedule for the day. The AI lists a series of meetings and meals throughout the day.\n",
      "Human: What would be a good time to meet?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We have a meeting scheduled for 10 am, but I have some availability in the afternoon around 2 pm. Would that work for you?'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good time to meet?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI with a hello. The AI responds with \"What\\'s up\" and the human says they are just hanging out. The AI mentions its busy schedule for the day, filled with meetings and meals.\\nHuman: What would be a good time to meet?\\nAI: I have some availability between 3pm and 5pm. Would that work for you?'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
